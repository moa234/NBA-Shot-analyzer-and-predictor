{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Map Reduce</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mrjob.job import MRJob\n",
    "# from mrjob.step import MRStep\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import threading\n",
    "from random import shuffle\n",
    "from collections import Counter\n",
    "from threading import Lock\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class classifier:\n",
    "    def __init__(self, input_file, output_dir, n_mappers, n_reducers, combiner, preprocess, sub_classifier_config):\n",
    "        self.input_file = input_file\n",
    "        self.output_dir = output_dir\n",
    "        self.n_mappers = n_mappers\n",
    "        self.n_reducers = n_reducers\n",
    "        self.combiner = combiner\n",
    "        self.preprocess = preprocess\n",
    "        self.config = sub_classifier_config\n",
    "    \n",
    "    def preprocess_data(self, df: pd.DataFrame):\n",
    "        self.labels: list = df[\"current shot outcome\"].unique().tolist() \n",
    "        df[\"current shot outcome\"] = df[\"current shot outcome\"].apply(lambda x: self.labels.index(x))\n",
    "        return df\n",
    "        \n",
    "        \n",
    "    def split_n_shuffle(self, file = None):\n",
    "\n",
    "        if self.input_file:\n",
    "            try:\n",
    "                df = pd.read_csv(self.input_file)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                return \n",
    "        df = file\n",
    "        split_size = self.n_mappers\n",
    "        headers = df.columns\n",
    "        chunks = np.array_split(df.to_numpy(), split_size)\n",
    "        shuffle(chunks)\n",
    "        list_of_df = [pd.DataFrame(data = chunk, columns = headers) for chunk in chunks]\n",
    "        self.temp_file_splits = []\n",
    "        for i, chunk_df in enumerate(list_of_df):\n",
    "            print(f\"Chunk {i+1}\")\n",
    "            self.temp_file_splits.append(f\"{self.output_dir}/chunk{i}.csv\")\n",
    "            chunk_df.to_csv(f\"{self.output_dir}/chunk{i}.csv\")\n",
    "            \n",
    "        \n",
    "    def run_mapper(self):\n",
    "        print(\"commencing threads with num of threads => \", len(self.temp_file_splits))\n",
    "        # Pass an iterable of input file paths to starmap\n",
    "        args = [temp_file for temp_file in self.temp_file_splits]\n",
    "        # print(args)\n",
    "        # Use starmap to map the mapper function to each input file\n",
    "        num_threads =  len(self.temp_file_splits)\n",
    "        # Create a list to store the threads\n",
    "        threads = []\n",
    "        results = []\n",
    "        lock = Lock()\n",
    "        # Create and start threads with sample data\n",
    "        for i in range(num_threads):\n",
    "            thread = threading.Thread(target=self.mapper, args=(args[i], results, lock))\n",
    "            thread.start()\n",
    "            threads.append(thread)\n",
    "        # Wait for all threads to finish (optional)\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "        # print(\"Done\")\n",
    "        # print(\"all threads are done...\", threads)\n",
    "        return results\n",
    "        \n",
    "    def reducer(self):\n",
    "        return list([tree[1] for tree in self.trees])\n",
    "    \n",
    "    def run_reducer(self):\n",
    "        return self.reducer()\n",
    "    \n",
    "                \n",
    "    def mapper(self, temp_file, results, lock):\n",
    "        print(\"thread started mapping on file => \", temp_file)\n",
    "        df = pd.read_csv(temp_file)\n",
    "        # if self.preprocess:\n",
    "        #   df = self.preprocess_data(df) \n",
    "        # print(df) \n",
    "        tree = DecisionTreeClassifier(criterion = self.config['criterion'], random_state = self.config['random_state'], max_depth = self.config['max_depth'])\n",
    "        tree.fit(df.drop(self.config[\"target\"], axis = 1), df[self.config[\"target\"]])\n",
    "        # print(\"thread with file %s is done\", temp_file)\n",
    "        with lock:\n",
    "            results.append((None, tree))\n",
    "        \n",
    "        \n",
    "    def run(self, file):\n",
    "        print(\"commencing splitting and shuffling...\")\n",
    "        self.split_n_shuffle(file)\n",
    "        print(\"splitting and shuffling is done, commencing mapping...\")\n",
    "        self.trees = self.run_mapper()\n",
    "        print(\"mapping is done, commencing reduction...\")\n",
    "        self.trees = self.run_reducer()\n",
    "        print(\"all done...\")\n",
    "        \n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for tree in self.trees:\n",
    "            predictions.append(tree.predict(X))\n",
    "        predictions = np.array(predictions)\n",
    "        final_predictions = []\n",
    "        for i in range(predictions.shape[1]):\n",
    "            final_predictions.append(Counter(predictions[:, i]).most_common(1)[0][0])\n",
    "        return np.array(final_predictions)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'feature1': [1, 2, 3, 4, 5],\n",
    "    'feature2': [5, 4, 3, 2, 1],\n",
    "    'target': [0, 1, 0, 1, 0]\n",
    "}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"criterion\" : \"gini\",\n",
    "    \"target\" : \"target\",\n",
    "    \"random_state\" : 52,\n",
    "    \"max_depth\": 5\n",
    "}\n",
    "mp = classifier(None, \"./data\", 5, 1, False, True, config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "commencing splitting and shuffling...\n",
      "Chunk 1\n",
      "Chunk 2\n",
      "Chunk 3\n",
      "Chunk 4\n",
      "Chunk 5\n",
      "splitting and shuffling is done, commencing mapping...\n",
      "commencing threads with num of threads =>  5\n",
      "thread started mapping on file =>  ./data/chunk0.csv\n",
      "thread started mapping on file =>  ./data/chunk1.csv\n",
      "thread started mapping on file =>  ./data/chunk2.csv\n",
      "thread started mapping on file =>  ./data/chunk3.csv\n",
      "thread started mapping on file =>  ./data/chunk4.csv\n",
      "mapping is done, commencing reduction...\n",
      "all done...\n"
     ]
    }
   ],
   "source": [
    "mp.run(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 2 features, but DecisionTreeClassifier is expecting 3 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m mp\u001b[38;5;241m.\u001b[39mpredict([[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m5\u001b[39m]])\n",
      "Cell \u001b[1;32mIn[2], line 93\u001b[0m, in \u001b[0;36mclassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     91\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tree \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrees:\n\u001b[1;32m---> 93\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mappend(tree\u001b[38;5;241m.\u001b[39mpredict(X))\n\u001b[0;32m     94\u001b[0m predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(predictions)\n\u001b[0;32m     95\u001b[0m final_predictions \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32md:\\conda\\Lib\\site-packages\\sklearn\\tree\\_classes.py:500\u001b[0m, in \u001b[0;36mBaseDecisionTree.predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict class or regression value for X.\u001b[39;00m\n\u001b[0;32m    478\u001b[0m \n\u001b[0;32m    479\u001b[0m \u001b[38;5;124;03mFor a classification model, the predicted class for each sample in X is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;124;03m    The predicted classes, or the predict values.\u001b[39;00m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    499\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 500\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X, check_input)\n\u001b[0;32m    501\u001b[0m proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[0;32m    502\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32md:\\conda\\Lib\\site-packages\\sklearn\\tree\\_classes.py:460\u001b[0m, in \u001b[0;36mBaseDecisionTree._validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    459\u001b[0m     force_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 460\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    461\u001b[0m     X,\n\u001b[0;32m    462\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mDTYPE,\n\u001b[0;32m    463\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    464\u001b[0m     reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    465\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m    466\u001b[0m )\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m    468\u001b[0m     X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc\n\u001b[0;32m    469\u001b[0m ):\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\conda\\Lib\\site-packages\\sklearn\\base.py:625\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 625\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32md:\\conda\\Lib\\site-packages\\sklearn\\base.py:414\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    416\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    417\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 2 features, but DecisionTreeClassifier is expecting 3 features as input."
     ]
    }
   ],
   "source": [
    "mp.predict([[1,5,1]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
